{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNET5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We describe how to built a convolution neural network similar to that described in <u>Gradient Based Learning Applied to Document Recognition</u> by LeCunn et al.. We built all the necessary layers/components  using `Theano` and test various gradient descent methods on the MNIST dataset. \n",
    "\n",
    "A convolution neural network (CNN) is a type of feed forward artificial neural netowrk that that utilizes convolutions to exploit <b>local connectivity</b>, in addition <b>weight sharing</b>. We begin by describing a discrete convolution in 1-D, followed by defining local connectivity and weigth sharing. \n",
    "\n",
    "A 1-D discrete convolution is described as \n",
    "<h5 align=center>\n",
    "$\n",
    "\\begin{align}\n",
    "o[n] &= f[n]\\ast g[n]\\\\ \n",
    "&= \\sum\\limits_{u\\in \\mathbb{R}} f[u]g[n-u]\\\\\n",
    "&= \\sum\\limits_{u\\in \\mathbb{R}} f[n-u]g[u]\\\\\n",
    "\\end{align}\n",
    "$\n",
    "</h5>\n",
    "\n",
    "<br><b>Local connectivity:</b> A CNN \"ensures that the learnt \"filters\" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to non-linear \"filters\" that become increasingly \"global\". This allows the network to first create good representations of small parts of the input, then assemble representations of larger areas from them. \n",
    "\n",
    "<img src=\"LocalConnectivity.png\" style=\"width:auto;height:128px;\">\n",
    "\n",
    "<br><b>Shared wieghts:</b> Given a filter we run the same filter for all positions in the image. In other words, all the pixel positions “share” the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer detect exactly the same feature. Replicating units in this way allows for features to be detected regardless of their position in the visual field, thus constituting the property of translation invariance.\" \n",
    "\n",
    "### Architecture\n",
    "\n",
    "The architecture that we will be building consists of a <b>convolution layer</b> followed by a <b>pooling layer</b>, a convolution layer, a pooling layer, a <b>fully connected layer</b>, and finaly a predictive layer. The model can be depicted by:\n",
    "\n",
    "<img src=\"architec2.png\" style=\"width:auto;height:228px;\">\n",
    "\n",
    "The <b>convolution layer</b> is the workhorse of the the CNN and does most of the computation. \"The conv layer's paramaters consist of a set of learnable filters, where every filter is small spatially, but extend through the full depth of the input volume. During the forward pass the filter slides accross the input computing a dot product between the filter and input at any given position. The network will learn filters that activate when a feature of interest is detected.\"\n",
    "\n",
    "The <b>pooling layers</b> is a downsampling operation which acts by reducing the spatial size of the representation while attempting to retain important information. Pooling works by partiting the input into a set of non-overlapping rectangles and, for each sub-region outputs one of the following: average of the values within a given sub-region, taking the largest element, or by computing the $l_2$ norm. \n",
    "\n",
    "The <b>fully connectected layer</b> (FC) is a traditional Multi Layer Perceptron. The term “Fully Connected” implies that every neuron in the previous layer is connected to every neuron on the next layer. The inputs from the last conv/pool layer are flattened and passed through the FC-layer. The activations are computed with a matrix multiplication followed by a bias offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano Code\n",
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\r\n",
      "   Creating library C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpyneqv_4u/m91973e5c136ea49268a916ff971b7377.lib and object C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpyneqv_4u/m91973e5c136ea49268a916ff971b7377.exp\r\n",
      "\n",
      "Using gpu device 0: GeForce 940M (CNMeM is enabled with initial size: 75.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "#### Libraries\n",
    "# Third Party Libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "The convolution layer performs a convolution operation on the input. It needs to take into accout the following arguments:\n",
    "\n",
    "<b>input:</b> The input feature map.\n",
    "<br><b>filter_shape:</b> The shape of the filter.\n",
    "<br><b>padding:</b> Inserts a 0-valued border of appropriate size around the input (image_shape). This gives us a little more control over the size of the feature map.  <br><b>stride:</b> The stride is the number of pixels by which we slide our filter over the input (`image_shape`).\n",
    "<br><b>activation_fn:</b> A nonlinear function used to transform our input; generally representing the rate of action potential firing for a given pixel. The purpose of which is to ensure that the representation in the input is mapped to a different space in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "\n",
    "    def __init__(self, input, filter_shape, image_shape, padding=(0, 0), \n",
    "                 stride=(1, 1), activation_fn=None):\n",
    "\n",
    "        assert image_shape[1] == filter_shape[1]\n",
    "\n",
    "        # rng = np.random.RandomState(seed)\n",
    "\n",
    "        self.input = input\n",
    "        self.filter_shape = filter_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "        fan_in = np.prod(filter_shape[1:])\n",
    "        fan_out = filter_shape[0]*np.prod(filter_shape[2:]) // 2\n",
    "        W_bound = np.sqrt(6/(fan_in+fan_out))\n",
    "        w = np.random.uniform(low=-W_bound, high=W_bound, size=filter_shape)\n",
    "        b_vals = np.random.uniform(size=filter_shape[0])\n",
    "\n",
    "        # Initiliaze weights with random variables\n",
    "        self.W = theano.shared(name='weights',\n",
    "                               value=w.astype(theano.config.floatX),\n",
    "                               borrow=True)\n",
    "        self.b = theano.shared(name='bias',\n",
    "                               value=b_vals.astype(theano.config.floatX), \n",
    "                               borrow=True)\n",
    "\n",
    "        conv_out = conv2d(input=input, filters=self.W, border_mode=padding,\n",
    "                          subsample=stride, filter_shape=filter_shape, \n",
    "                          input_shape=image_shape)\n",
    "\n",
    "        l_output = conv_out + self.b.dimshuffle(('x', 0, 'x', 'x'))\n",
    "        self.output = (l_output if activation_fn is None \n",
    "                       else activation_fn(l_output))\n",
    "\n",
    "        # Parameters of the model\n",
    "        self.params = [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer\n",
    "As described above the pooling layer is a downsampling operation, as such we decided to use `MAX` value in each sub-region. Hence, to construct this layer we need to take the following arguments into consideration:\n",
    "\n",
    "<b>input:</b> The input feature map. \n",
    "<br><b>pool_shape:</b> The size of the window. \n",
    "<br><b>ignore_border:</b> If set to `True` then right and/or bottom row/column will be ignored if it cannot be fully covered by the window (`pool_shape`).\n",
    "<br><b>activation_fn:</b> A nonlinear function used to transform our input; generally representing the rate of action potential firing for a given pixel. The purpose of which is to ensure that the representation in the input is mapped to a different space in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoolingLayer(object):\n",
    "\n",
    "    def __init__(self, input, pool_shape=(2, 2), ignore_border=True,\n",
    "                 activation_fn=None):\n",
    "        self.input = input\n",
    "        self.pool_shape = pool_shape\n",
    "        self.ignore_border = ignore_border\n",
    "\n",
    "        l_output = pool.pool_2d(input=input, ds=pool_shape, \n",
    "                                ignore_border=self.ignore_border)\n",
    "\n",
    "        self.output = (l_output if activation_fn is None \n",
    "                       else activation_fn(l_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer\n",
    "The Fully Connected layer is a traditional Multi Layer Perceptron hence we need to take into account the following arguments:\n",
    "\n",
    "<b>input:</b> The input feature map\n",
    "<br><b>n_in:</b> The number of input neurons \n",
    "<br><b>n_out:</b> The number of output neurons.\n",
    "<br><b>W:</b> (Optional) Load pretrained weights\n",
    "<br><b>b:</b> (Optional) Load pretrained biases.\n",
    "<br><b>activation_fn:</b> A nonlinear function used to transform our input; generally representing the rate of action potential firing for a given pixel. The purpose of which is to ensure that the representation in the input is mapped to a different space in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FC(object):\n",
    "\n",
    "    def __init__(self, input, n_in, n_out, W=None, b=None, seed=35,\n",
    "                 activation_fn=None):\n",
    "\n",
    "        # rng = np.random.RandomState(seed)\n",
    "\n",
    "        self.input = input\n",
    "\n",
    "        if W is None:\n",
    "            W_values = np.random.uniform(low=-np.sqrt(6./(n_in+n_out)),\n",
    "                                   high=np.sqrt(6./(n_in+n_out)),\n",
    "                                   size=(n_out, n_in)).astype(theano.config.floatX)\n",
    "\n",
    "            if activation_fn == theano.tensor.nnet.sigmoid:\n",
    "                W_values *= 4\n",
    "\n",
    "            W = theano.shared(name='Weights', value=W_values, borrow=True)\n",
    "\n",
    "\n",
    "        if b is None:\n",
    "            b_values = np.zeros(n_out, dtype=theano.config.floatX)\n",
    "            b = theano.shared(name='bias', value=b_values, borrow=True)\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        l_output = (T.dot(self.W, input.T)).T + self.b\n",
    "        self.output = (l_output if activation_fn is None \n",
    "                       else activation_fn(l_output))\n",
    "\n",
    "        self.params = [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model\n",
    "### Activation Function & Regularization\n",
    "We decided to use the `Exponential Linear Unit (ELU)` as described in <u>Fast and accurate deep network learning by exponetial lienar units</u> by Clevert et al., since this non-linear function displayed quicker convergence and yielded a higher validation score relative to a `sigmoid`, `tanh`, or `ReLu` function. Furthermore, to reduce overfitting we used $l_2$ regularization which acts by penalizing our model by adding a complexity term that would yields a higher loss for more complex models. Both the activation function and regularization method or defined below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elu(x, alpha=1.0):\n",
    "    return T.switch(x > 0, x, T.exp(x)-1)\n",
    "\n",
    "def l2_reg(x, lmbd=0.05):\n",
    "    \"\"\"\n",
    "    L_2 regularization \n",
    "    \"\"\"\n",
    "\n",
    "    l2 = 0\n",
    "    for elements in x:\n",
    "        l2 += T.sum(elements[0]**2)\n",
    "\n",
    "    return lmbd / 2 * l2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4(name='X', dtype=theano.config.floatX) \n",
    "Y = T.imatrix(name='Y')\n",
    "y = T.ivector(name='y')\n",
    "lr = T.scalar(name='learning_rate', dtype=theano.config.floatX)\n",
    "\n",
    "nkerns = [8, 32]\n",
    "batch_size = 256\n",
    "act_f = elu\n",
    "\n",
    "conv_layer1 = ConvLayer(input=X, \n",
    "                        filter_shape=(nkerns[0], 1, 3, 3), \n",
    "                        image_shape=(batch_size, 1, 28, 28),\n",
    "                        activation_fn=None)\n",
    "pool_layer1 = PoolingLayer(input=conv_layer1.output,\n",
    "                           activation_fn=act_f)\n",
    "conv_layer2 = ConvLayer(input=pool_layer1.output,\n",
    "                        filter_shape=(nkerns[1], nkerns[0], 5, 5), \n",
    "                        image_shape=(batch_size, nkerns[0], 13, 13),\n",
    "                        activation_fn=None)\n",
    "pool_layer2 = PoolingLayer(input=conv_layer2.output,\n",
    "                           activation_fn=act_f)\n",
    "\n",
    "# outputs from convolution network need to be flattend before being \n",
    "# passed through to the the fully-connected layer\n",
    "fc_layer_input = pool_layer2.output.flatten(2) \n",
    "\n",
    "fc_layer1 = FC(input=fc_layer_input,\n",
    "                n_in=nkerns[1] * 4 * 4,\n",
    "                n_out=512,\n",
    "                activation_fn=act_f)\n",
    "fc_layer2 = FC(input=fc_layer1.output,\n",
    "               n_in=512,\n",
    "               n_out=10,\n",
    "               activation_fn=act_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "Since we will be performing classification we will be using the categorical cross entropy function as our cost function which is also the function which we seek to minimize. The cross entropy function is defined to be:\n",
    "\n",
    "<h5 align=\"center\">\n",
    "$\n",
    "\\begin{equation}\n",
    "H(p, q) = - \\sum\\limits_{x} p(x)\\log\\big(q(x)\\big)\n",
    "\\end{equation}\n",
    "$\n",
    "</h5>\n",
    "\n",
    "where $p(x)$ is the true distribution (the true label) and $q(x)$ is coding distribution (the predicted value). Due to $\\log(\\cdot) \\ \\in \\ (0, \\infty)$ we need to have $q(x) \\in (0, 1)$ and this is accomplished by passing our input into a `softmax`, a generalization of the logistic function that \"squashes\" a K-dimensional vector $\\mathbf{z}$  of arbitrary real values to a K-dimensional vector $\\sigma(\\mathbf{z})$ of real values in the range $(0, 1)$ that add up to 1 and is defined to be \n",
    "\n",
    "<h5 align=\"center\">\n",
    "$\n",
    "\\begin{equation}\n",
    "\\sigma(\\mathbf{z}) = \\frac{\\exp(z_j)}{\\sum_{k=1}^K \\exp(z_k)} \\text{ for } j =1\\ldots K\n",
    "\\end{equation}\n",
    "$\n",
    "</h5>\n",
    "\n",
    "In order to minimize the `cross entropy` function we need to take its gradient with respect to the paramaters in the network, which are those present in both fully connected layers and in both convolution layers. \n",
    "\n",
    "The code below show how to accomplish this using `Theano`. We begin by defining the paramaters in the network. We then pass the output of the final fully connected layer into a `softmax` function to generate a probaility distribution which is followed by passing our `softmax` values into the `categorical cros sentropy` function with $l_2$ regularization. Finally, we call `tensor.grad()` to get the gradient with respect to `params`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = fc_layer2.params + fc_layer1.params\\\n",
    "       + conv_layer2.params + conv_layer1.params\n",
    "    \n",
    "cost_input = T.nnet.nnet.softmax(fc_layer2.output)\n",
    "cost = T.mean(T.nnet.nnet.categorical_crossentropy(cost_input, Y)) \\\n",
    "     + l2_reg(params)\n",
    "\n",
    "grads = T.grad(cost, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Methods (SGD)\n",
    "We present three (3) different SGD algorithm used to minimize our cost function. For more option we encourage the reader to see <a href=\"https://github.com/LukaszObara/Theano_gradient_descent\">Theano_gradient_descent</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla SGD\n",
    "This is the simplest form of update, it changes the parameters along the negative gradient direction. Vanilla SGD suffers from a slow convergence and displays a difficutly escaping from a saddle point. \n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "<h5 align=\"center\">\n",
    "$\n",
    "x_{t+1} = x_{t} - \\eta \\nabla C\n",
    "$\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(l_rate, parameters, grads): \n",
    "    \n",
    "    updates = []\n",
    "    for param, grad in zip(parameters, grads):\n",
    "        updates.append((param, param - l_rate * grad))\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum\n",
    "Momentum is a varient of Vanilla SGD that helps accelerate SGD in the relevant direction and dampens oscillations. It does this by adding a fraction $\\gamma$ of the update vector of the past time step to the current update vector. Nevertheless, like Vanilla SGD it still has difficulty escaping a saddle point. \n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "<h5 align=\"center\">\n",
    "$\\begin{align}\n",
    "v_{t+1} &= \\gamma v_t + \\eta \\nabla C\\\\\n",
    "x_{t+1} &=  x_t- v_{t+1}\n",
    "\\end{align}$\n",
    "</h5>\n",
    "\n",
    "where $v_t$ can be considered as the velocity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def momentum(l_rate, parameters, grads, momentum=0.9):\n",
    "    \n",
    "    def update_rule(param, velocity, df):\n",
    "        v_next = momentum * velocity - l_rate * df\n",
    "        updates = (param, param+v_next), (velocity, v_next)\n",
    "\n",
    "        return updates\n",
    "\n",
    "    assert momentum <=1 and momentum >= 0\n",
    "\n",
    "    velocities = [theano.shared(name='v_%s' % param,\n",
    "                                value=param.get_value() * 0., \n",
    "                                broadcastable=param.broadcastable) \n",
    "                  for param in parameters]\n",
    "\n",
    "    updates = []\n",
    "    for p, v, g in zip(parameters, velocities, grads):\n",
    "        param_updates, vel_updates = update_rule(p, v, g)\n",
    "        updates.append(param_updates)\n",
    "        updates.append(vel_updates)\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp\n",
    "The update rule that yielded the best results was RMSProp, which is an adaptive learning rate method. This allows the the learning rate to be adaptively tuned after each epoch, eliminating the need for any type of annealing (not discussed). In addition adaptive learning rates are well-behaved for a broader range of hyperparameter values than the methods presents above. In the case of RMSProp the adaptive learning is accomplished by dividing the learning rate by an exponentially decaying average of squared gradients. Relative to the methods discussed above it does not seem to suffer from being stuck in a saddle point. \n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "<h5 align=\"center\">\n",
    "$\\begin{align}\n",
    "E[\\nabla C^2]_{t} &= \\delta*E[\\nabla C^2]_{t-1} + (1-\\delta)\\nabla C^2_t\\\\\n",
    "x_{t+1} &=  x_t- \\eta\\frac{1}{\\sqrt{E[g^2]_t +\\epsilon}}\\nabla C_t\n",
    "\\end{align}$\n",
    "</h5>\n",
    "\n",
    "where $E[\\nabla C^2]$ is the cache value that stores a weighted sum of previous cache values and gradients squared. It is then used to normalize the parameter update step, element-wise. $\\delta$ is the decay rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsprop(l_rate, d_rate=0.9, epsilon=1e-6, parameters=None, grads=None):\n",
    "\n",
    "    one = T.constant(1.0)\n",
    "\n",
    "    def update_rule(param, cache, df):\n",
    "        cache_val = d_rate * cache + (one-d_rate) * df**2\n",
    "        x = l_rate * df / (T.sqrt(cache_val) + epsilon)\n",
    "        updates = (param, param-x), (cache, cache_val)\n",
    "\n",
    "        return updates\n",
    "\n",
    "    caches = [theano.shared(name='c_{}'.format(param),\n",
    "                                value=param.get_value() * 0., \n",
    "                                broadcastable=param.broadcastable) \n",
    "              for param in parameters]\n",
    "\n",
    "    updates = []\n",
    "    for p, c, g in zip(parameters, caches, grads):\n",
    "        param_updates, cache_updates = update_rule(p, c, g)\n",
    "        updates.append(param_updates)\n",
    "        updates.append(cache_updates)\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validating\n",
    "To train the network we need to define a training and validation function using `theano.function()`. Using RMSProp as our SGD method we create the necessary functions below.  All the functions are defined in a similar manner, both validation function and a prediction functions omit the `update` argument, since they are used for pushing the data forward.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpdfal2rjh/m9a6bd0eb5ed5c92e91261282fc495cb4.lib and object C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpdfal2rjh/m9a6bd0eb5ed5c92e91261282fc495cb4.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpr3nlvjlf/m848dd898e26d545ff6290e3aa98de3d5.lib and object C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpr3nlvjlf/m848dd898e26d545ff6290e3aa98de3d5.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpr5xt2c3q/mcaee517fdbbfe5601d70389b5e9a720a.lib and object C:/Users/lukas/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-3.5.2-64/tmpr5xt2c3q/mcaee517fdbbfe5601d70389b5e9a720a.exp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = theano.function(inputs=[X, Y, lr], outputs=cost, \n",
    "                        updates=rmsprop(l_rate=lr, parameters=params, \n",
    "                                     grads=grads),\n",
    "                        allow_input_downcast=True)\n",
    "\n",
    "# Validation results\n",
    "pred_result = cost_input.argmax(axis=1)\n",
    "accu = theano.function(inputs=[X, y], outputs=T.sum(T.eq(pred_result, y)), \n",
    "                       allow_input_downcast=True)\n",
    "\n",
    "pred = theano.function(inputs=[X], outputs=pred_result, \n",
    "                       allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The last stage involves creating a function that shuffles and partitions into appropriate sized batches before being processed further during each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(training_data, validation_data, test_data=None,\n",
    "                learning_rate=1e-4, epochs=100):\n",
    "\n",
    "    print('---Training Model---')\n",
    "    predicted_results = [] \n",
    "\n",
    "    total_values, total_val_values = len(training_data), len(validation_data)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Currently on epoch {}'.format(epoch+1))\n",
    "        np.random.shuffle(training_data)\n",
    "\n",
    "        mini_batches = [training_data[k: k+batch_size]\n",
    "                        for k in range(0, total_values, batch_size)] \n",
    "        validation_batches = [validation_data[m: m+batch_size]\n",
    "                              for m in range(0, total_val_values, batch_size)]\n",
    "\n",
    "        training_cost, accuracy = 0, 0\n",
    "        training_cost_list, accuracy_list = [], []\n",
    "\n",
    "        for mini_batch in mini_batches:\n",
    "            labels = mini_batch[:, 0]\n",
    "            label_matrix = np.zeros(shape=(256, 10), dtype=theano.config.floatX)\n",
    "\n",
    "            for i, label in enumerate(labels):\n",
    "                vec = scalar_to_vec(int(label), 10)\n",
    "                label_matrix[i] = vec\n",
    "\n",
    "            digits = mini_batch[:, 1:]/255\n",
    "            digits = digits.reshape(-1, 1, 28, 28)\n",
    "            cost_ij = train(digits, label_matrix, learning_rate)\n",
    "            training_cost += cost_ij\n",
    "\n",
    "        for val_batch in validation_batches:\n",
    "            labels = mini_batch[:, 0]\n",
    "            label_matrix = np.zeros(shape=(256, 10), dtype=theano.config.floatX)\n",
    "\n",
    "            for i, label in enumerate(labels):\n",
    "                vec = scalar_to_vec(int(label), 10)\n",
    "                label_matrix[i] = vec\n",
    "\n",
    "            digits = mini_batch[:, 1:]/255\n",
    "            digits = digits.reshape(-1, 1, 28, 28)\n",
    "            accuracy += accu(digits, labels)\n",
    "\n",
    "        training_cost_list.append(training_cost/total_values)\n",
    "        accuracy_list.append(accuracy/total_val_values)\n",
    "\n",
    "        print('The accuracy is: {}'.format(accuracy/total_val_values))\n",
    "        print('The loss is: {}'.format(training_cost/total_values))\n",
    "        print('--------------------------')\n",
    "\n",
    "    if np.any(test_data):\n",
    "        print('===================================')\n",
    "        print('Using test data to predict results')\n",
    "        total_values = len(test_data)\n",
    "\n",
    "        mini_batches = [test_data[k: k+batch_size]\n",
    "                        for k in range(0, total_values, batch_size)] \n",
    "\n",
    "        for mini_batch in mini_batches:\n",
    "            digits = mini_batch[:, :]/255\n",
    "            digits = digits.reshape(-1, 1, 28, 28)\n",
    "            result = pred(digits)\n",
    "            predicted_results = np.append(predicted_results, result)\n",
    "\n",
    "        print('Done')\n",
    "\n",
    "    return training_cost_list, accuracy_list, predicted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running The Code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    location = 'C:\\\\...\\\\MNIST\\\\augmented_train.npy'\n",
    "    location_test = 'C:\\...\\\\MNIST\\\\test_padded.npy'\n",
    "    data = np.load(location)\n",
    "    data_train, data_val = train_test_split(data, test_size=12800, \n",
    "                                            random_state=23)\n",
    "    test_val = np.load(location_test)\n",
    "\n",
    "    t_data, a_data, label = train_model(data_train, data_val, test_val,\n",
    "                                        learning_rate=1e-4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
